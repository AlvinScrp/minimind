# æœ‰ç›‘ç£å¾®è°ƒSFT

# ä»£ç 

å¤§ä½“ç»“æ„ç±»ä¼¼Pretrainï¼Œä¸‹é¢åˆ†æåŒºåˆ«

## **1. æ ¸å¿ƒåŒºåˆ«ï¼šè®­ç»ƒç›®æ ‡ä¸åŒ**

### âœ³ï¸ `train_pretrain.py`â€‹ï¼šç”¨äº**è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒ**

* ä½¿ç”¨**æœªæ ‡æ³¨çš„å¤§é‡æ–‡æœ¬æ•°æ®**ï¼ˆä¾‹å¦‚ Wikipediaã€ä¹¦ç±ç­‰ï¼‰
* å­¦ä¹ è¯­è¨€ç»“æ„ã€ä¸Šä¸‹æ–‡ä¾èµ–ã€è¯æ³•å’Œè¯­æ³•çŸ¥è¯†
* ç›®æ ‡æ˜¯ä»é›¶å­¦ä¹ è¯­è¨€å»ºæ¨¡èƒ½åŠ›

ğŸ“Œ **æ•°æ®åŠ è½½éƒ¨åˆ†ï¼š**

```py
from model.dataset import PretrainDataset
...
train_ds = PretrainDataset(args.data_path, tokenizer, max_length=lm_config.max_seq_len)
```

---

### âœ³ï¸ `train_full_sft.py`â€‹ï¼šç”¨äº**ç›‘ç£å¾®è°ƒï¼ˆSupervised Fine-tuning, SFTï¼‰**

* ä½¿ç”¨**å·²æ ‡æ³¨æ•°æ®**ï¼ˆä¾‹å¦‚ prompt + responseï¼‰
* ç›®æ ‡æ˜¯è®©æ¨¡å‹å­¦ä¼šå¦‚ä½•æŒ‰ç…§ç”¨æˆ·æŒ‡ä»¤äº§å‡ºåˆé€‚å›ç­”
* å»ºç«‹åœ¨é¢„è®­ç»ƒæ¨¡å‹çš„åŸºç¡€ä¸Šç»§ç»­è®­ç»ƒï¼Œå¼ºåŒ–æ¨¡å‹çš„â€œè¡Œä¸ºâ€

ğŸ“Œ **æ•°æ®åŠ è½½éƒ¨åˆ†ï¼š**

```py
from model.dataset import SFTDataset
...
train_ds = SFTDataset(args.data_path, tokenizer, max_length=lm_config.max_seq_len)
```

---

## **2. æ¨¡å‹æƒé‡åŠ è½½æ–¹å¼ä¸åŒ**

### `train_pretrain.py`â€‹ æ˜¯ä»**éšæœºåˆå§‹åŒ–**å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼š

```py
model = MiniMindLM(lm_config).to(args.device)
```

### `train_full_sft.py`â€‹ åˆ™æ˜¯ä»**å·²æœ‰çš„é¢„è®­ç»ƒæ¨¡å‹æƒé‡**ç»§ç»­è®­ç»ƒï¼š

```py
ckp = f'./out/pretrain_{lm_config.dim}{moe_path}.pth'
state_dict = torch.load(ckp, map_location=args.device)
model.load_state_dict(state_dict, strict=False)
```

---

## **3. é»˜è®¤è¶…å‚æ•°ä¸åŒ**

* â€‹`train_pretrain.py`â€‹ é»˜è®¤å­¦ä¹ ç‡æ›´é«˜ `5e-4`â€‹ï¼Œå› ä¸ºè®­ç»ƒä»å¤´å¼€å§‹ï¼Œéœ€è¦æ›´å¿«æ”¶æ•›ã€‚
* â€‹`train_full_sft.py`â€‹ é»˜è®¤å­¦ä¹ ç‡æ›´å° `5e-5`â€‹ï¼Œé¿å…åœ¨å¾®è°ƒæ—¶ç ´åå·²å­¦çŸ¥è¯†ã€‚
* â€‹`accumulation_steps`â€‹ ä¹Ÿä¸åŒï¼ˆåˆ†åˆ«æ˜¯ 8 å’Œ 1ï¼‰

ğŸ“Œ å¯¹åº”ä»£ç ï¼š

```py
# pretrain
parser.add_argument("--learning_rate", type=float, default=5e-4)
parser.add_argument("--accumulation_steps", type=int, default=8)

# sft
parser.add_argument("--learning_rate", type=float, default=5e-5)
parser.add_argument("--accumulation_steps", type=int, default=1)
```

---

# ä½¿ç”¨

æœ€å°åŒ–è®­ç»ƒï¼Œä»…ä¾›æœ¬åœ°æˆ–è€…ç”¨æ¯”è¾ƒä¾¿å®œçš„3090ï¼Œ4090å®¹å™¨äº‘è¿›è¡Œè®­ç»ƒ

å…‹éš†å®Œé¡¹ç›®ä¹‹åæ‰§è¡Œä¸‹é¢çš„ä¸‹è½½æ•°æ®é›†ï¼ˆ`1.6GB`â€‹ï¼‰

```shell
mkdir -p dataset
cd dataset
wget https://www.modelscope.cn/datasets/gongjy/minimind_dataset/resolve/master/sft_mini_512.jsonl
```

è‡ªè¡Œcdå›æ ¹ç›®å½•

æŸ¥çœ‹æ•°æ®é›†æƒ…å†µï¼ˆå¯¹è¯ï¼‰

```shell
head -n 1 dataset/sft_mini_512.jsonl
{"conversations": [{"role": "user", "content": "è¯·å‘Šè¯‰æˆ‘åœ¨ä¸­å›½å¤ä»£çš„â€œå››å¤§å‘æ˜â€æ˜¯ä»€ä¹ˆï¼Ÿ"}, {"role": "assistant", "content": "ä¸­å›½å¤ä»£çš„â€œå››å¤§å‘æ˜â€æ˜¯æŒ‡é€ çº¸æœ¯ã€å°åˆ·æœ¯ã€ç«è¯å’ŒæŒ‡å—é’ˆã€‚è¿™å››é¡¹å‘æ˜å¯¹ä¸–ç•Œæ–‡æ˜çš„å‘å±•äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ï¼š\n\n1. **é€ çº¸æœ¯**ï¼šæ®å²ä¹¦è®°è½½ï¼Œä¸œæ±‰æ—¶æœŸçš„è”¡ä¼¦æ”¹è¿›äº†é€ çº¸å·¥è‰ºï¼Œä½¿å¾—çº¸å¼ çš„ç”Ÿäº§æ›´åŠ ä¾¿æ·ã€æˆæœ¬æ›´ä½ï¼Œè´¨é‡ä¹Ÿæ›´åŠ ä¼˜è‰¯ã€‚è¿™ä¸€å‘æ˜æå¤§åœ°ä¿ƒè¿›äº†æ–‡åŒ–çš„ä¼ æ’­å’Œä¿å­˜ã€‚\n\n2. **å°åˆ·æœ¯**ï¼šä¸­å›½å¤ä»£çš„å°åˆ·æœ¯æœ€æ—©å¯ä»¥è¿½æº¯åˆ°å”ä»£çš„é›•ç‰ˆå°åˆ·ï¼Œåˆ°äº†å®‹ä»£å‘å±•å‡ºäº†æ´»å­—å°åˆ·æŠ€æœ¯ã€‚å°åˆ·æœ¯çš„å‘æ˜æå¤§åœ°ä¿ƒè¿›äº†çŸ¥è¯†çš„ä¼ æ’­ï¼Œé™ä½äº†ä¹¦ç±çš„æˆæœ¬ï¼Œå¯¹æ•™è‚²å’Œæ–‡åŒ–çš„å‘å±•èµ·åˆ°äº†é‡è¦çš„æ¨åŠ¨ä½œç”¨ã€‚\n\n3. **ç«è¯**ï¼šç«è¯æœ€åˆæ˜¯åœ¨å”ä»£è¢«å‘ç°çš„ï¼Œæœ€åˆå¯èƒ½ç”¨äºåŒ»ç–—æˆ–ç‚¼é‡‘æœ¯ã€‚åˆ°äº†å®‹ä»£ï¼Œäººä»¬å¼€å§‹å°†ç«è¯ç”¨äºå†›äº‹ç›®çš„ï¼Œå‘æ˜äº†å„ç§ç«å™¨ã€‚ç«è¯çš„å‘æ˜æ”¹å˜äº†æˆ˜äº‰çš„é¢è²Œï¼Œå¯¹ä¸–ç•Œå†›äº‹æŠ€æœ¯çš„å‘å±•äº§ç”Ÿäº†é‡å¤§å½±å“ã€‚\n\n4. **æŒ‡å—é’ˆ**ï¼šæŒ‡å—é’ˆæœ€åˆåœ¨ä¸­å›½è¢«ç”¨äºé£æ°´æµ‹é‡ï¼Œåæ¥é€æ¸å‘å±•æˆä¸ºèˆªæµ·å¯¼èˆªçš„é‡è¦å·¥å…·ã€‚è¿™ä¸€å‘æ˜æå¤§åœ°ä¿ƒè¿›äº†æµ·ä¸Šèˆªè¡ŒæŠ€æœ¯çš„å‘å±•ï¼Œå¯¹äºæ–°èˆªè·¯çš„å¼€è¾Ÿå’Œä¸–ç•Œåœ°ç†å¤§å‘ç°èµ·åˆ°äº†å…³é”®ä½œç”¨ã€‚\n\nè¿™å››é¡¹å‘æ˜ä¸ä»…åœ¨ä¸­å›½å†å²ä¸Šå æœ‰é‡è¦åœ°ä½ï¼Œè€Œä¸”å¯¹å…¨ä¸–ç•Œçš„ç§‘æŠ€è¿›æ­¥å’Œæ–‡æ˜å‘å±•éƒ½äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚"}]}
```

æ‰§è¡Œé¢„è®­ç»ƒ

batch_size32çš„æ—¶å€™å¤§æ¦‚å 7gæ˜¾å­˜ï¼Œå› ä¸ºæˆ‘çš„3080æœ‰20gï¼Œæ‰€ä»¥å¼€64ï¼Œæ€»å ç”¨14gä¸åˆ°

```shell
python train_full_sft.py --batch_size 64 --dim 512 --n_layers 8 --max_seq_len 512 --out_dir out --data_path ./dataset/sft_mini_512.jsonl
```

![image](assets/image-20250415152809-mhn02lz.png)

```shell
Epoch:[1/1](18800/18981) loss:1.892 lr:0.000005011218 epoch_Time:1.0min:
Epoch:[1/1](18900/18981) loss:1.885 lr:0.000005002247 epoch_Time:1.0min:
```

è¿è¡Œæµ‹è¯•

```shell
python eval_model.py --model_mode 0 --dim 512 --n_layers 8 --out_dir out --load 0
```

èƒ½å¤Ÿè¾“å‡ºç±»ä¼¼æ­£å¸¸å¯¹è¯çš„å›ç­”

![image](assets/image-20250416171515-1pguj6f.png)
